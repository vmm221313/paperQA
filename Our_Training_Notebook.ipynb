{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qUeK5JoF5uiW",
        "outputId": "e3829ddb-62f9-4779-fab1-5673bed18190"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'EndEval'...\n",
            "remote: Enumerating objects: 91, done.\u001b[K\n",
            "remote: Counting objects: 100% (91/91), done.\u001b[K\n",
            "remote: Compressing objects: 100% (89/89), done.\u001b[K\n",
            "remote: Total 91 (delta 38), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (91/91), 58.38 KiB | 1.46 MiB/s, done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://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@github.com/InterIITDevRev/EndEval.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RSZBA9tH6usT",
        "outputId": "dff3f5d5-37d3-4f5c-b988-3e77a8cad982"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/EndEval\n"
          ]
        }
      ],
      "source": [
        "%cd EndEval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hNMKxy74-ffI",
        "outputId": "2fada7ab-7b1e-4e89-b105-05040b9c47c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "remote: Enumerating objects: 5, done.\u001b[K\n",
            "remote: Counting objects:  20% (1/5)\u001b[K\rremote: Counting objects:  40% (2/5)\u001b[K\rremote: Counting objects:  60% (3/5)\u001b[K\rremote: Counting objects:  80% (4/5)\u001b[K\rremote: Counting objects: 100% (5/5)\u001b[K\rremote: Counting objects: 100% (5/5), done.\u001b[K\n",
            "remote: Compressing objects:  33% (1/3)\u001b[K\rremote: Compressing objects:  66% (2/3)\u001b[K\rremote: Compressing objects: 100% (3/3)\u001b[K\rremote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 3 (delta 2), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects:  33% (1/3)\rUnpacking objects:  66% (2/3)\rUnpacking objects: 100% (3/3)\rUnpacking objects: 100% (3/3), 694 bytes | 694.00 KiB/s, done.\n",
            "From https://github.com/InterIITDevRev/EndEval\n",
            " * branch            main       -> FETCH_HEAD\n",
            "   378d3f0..11849a9  main       -> origin/main\n",
            "Updating 378d3f0..11849a9\n",
            "Fast-forward\n",
            " config.yaml | 4 \u001b[32m++\u001b[m\u001b[31m--\u001b[m\n",
            " 1 file changed, 2 insertions(+), 2 deletions(-)\n"
          ]
        }
      ],
      "source": [
        "!git pull origin main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wl5nJeDI6xqB",
        "outputId": "0c208f2d-650d-4a23-91de-60eacb2493a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "data-dir/corenlp\n",
            "Will download to: data-dir/corenlp\n",
            "/tmp /content/EndEval\n",
            "--2023-02-05 04:55:06--  http://nlp.stanford.edu/software/stanford-corenlp-full-2017-06-09.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/software/stanford-corenlp-full-2017-06-09.zip [following]\n",
            "--2023-02-05 04:55:06--  https://nlp.stanford.edu/software/stanford-corenlp-full-2017-06-09.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 FOUND\n",
            "Location: https://downloads.cs.stanford.edu/nlp/software/stanford-corenlp-full-2017-06-09.zip [following]\n",
            "--2023-02-05 04:55:07--  https://downloads.cs.stanford.edu/nlp/software/stanford-corenlp-full-2017-06-09.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 390211140 (372M) [application/zip]\n",
            "Saving to: ‘stanford-corenlp-full-2017-06-09.zip’\n",
            "\n",
            "stanford-corenlp-fu 100%[===================>] 372.13M  5.10MB/s    in 70s     \n",
            "\n",
            "2023-02-05 04:56:17 (5.35 MB/s) - ‘stanford-corenlp-full-2017-06-09.zip’ saved [390211140/390211140]\n",
            "\n",
            "Archive:  stanford-corenlp-full-2017-06-09.zip\n",
            "   creating: stanford-corenlp-full-2017-06-09/\n",
            "  inflating: stanford-corenlp-full-2017-06-09/xom-1.2.10-src.jar  \n",
            "  inflating: stanford-corenlp-full-2017-06-09/CoreNLP-to-HTML.xsl  \n",
            "  inflating: stanford-corenlp-full-2017-06-09/README.txt  \n",
            "  inflating: stanford-corenlp-full-2017-06-09/jollyday-0.4.9-sources.jar  \n",
            "  inflating: stanford-corenlp-full-2017-06-09/LIBRARY-LICENSES  \n",
            "   creating: stanford-corenlp-full-2017-06-09/sutime/\n",
            "  inflating: stanford-corenlp-full-2017-06-09/sutime/defs.sutime.txt  \n",
            "  inflating: stanford-corenlp-full-2017-06-09/sutime/english.sutime.txt  \n",
            "  inflating: stanford-corenlp-full-2017-06-09/sutime/english.holidays.sutime.txt  \n",
            "  inflating: stanford-corenlp-full-2017-06-09/stanford-corenlp-3.8.0-javadoc.jar  \n",
            " extracting: stanford-corenlp-full-2017-06-09/ejml-0.23-src.zip  \n",
            "  inflating: stanford-corenlp-full-2017-06-09/stanford-corenlp-3.8.0-models.jar  \n",
            "  inflating: stanford-corenlp-full-2017-06-09/input.txt.xml  \n",
            "  inflating: stanford-corenlp-full-2017-06-09/build.xml  \n",
            "  inflating: stanford-corenlp-full-2017-06-09/pom.xml  \n",
            "   creating: stanford-corenlp-full-2017-06-09/tokensregex/\n",
            "  inflating: stanford-corenlp-full-2017-06-09/tokensregex/color.input.txt  \n",
            "  inflating: stanford-corenlp-full-2017-06-09/tokensregex/retokenize.txt  \n",
            "  inflating: stanford-corenlp-full-2017-06-09/tokensregex/color.properties  \n",
            "  inflating: stanford-corenlp-full-2017-06-09/tokensregex/color.rules.txt  \n",
            "  inflating: stanford-corenlp-full-2017-06-09/javax.json-api-1.0-sources.jar  \n",
            "  inflating: stanford-corenlp-full-2017-06-09/protobuf.jar  \n",
            "  inflating: stanford-corenlp-full-2017-06-09/StanfordDependenciesManual.pdf  \n",
            "   creating: stanford-corenlp-full-2017-06-09/patterns/\n",
            "  inflating: stanford-corenlp-full-2017-06-09/patterns/example.properties  \n",
            " extracting: stanford-corenlp-full-2017-06-09/patterns/otherpeople.txt  \n",
            " extracting: stanford-corenlp-full-2017-06-09/patterns/goldplaces.txt  \n",
            "  inflating: stanford-corenlp-full-2017-06-09/patterns/stopwords.txt  \n",
            "  inflating: stanford-corenlp-full-2017-06-09/patterns/presidents.txt  \n",
            "  inflating: stanford-corenlp-full-2017-06-09/patterns/names.txt  \n",
            " extracting: stanford-corenlp-full-2017-06-09/patterns/places.txt  \n",
            "  inflating: stanford-corenlp-full-2017-06-09/patterns/goldnames.txt  \n",
            "  inflating: stanford-corenlp-full-2017-06-09/slf4j-simple.jar  \n",
            "  inflating: stanford-corenlp-full-2017-06-09/input.txt  \n",
            "  inflating: stanford-corenlp-full-2017-06-09/joda-time.jar  \n",
            "  inflating: stanford-corenlp-full-2017-06-09/xom.jar  \n",
            "  inflating: stanford-corenlp-full-2017-06-09/StanfordCoreNlpDemo.java  \n",
            "  inflating: stanford-corenlp-full-2017-06-09/slf4j-api.jar  \n",
            "  inflating: stanford-corenlp-full-2017-06-09/ejml-0.23.jar  \n",
            "  inflating: stanford-corenlp-full-2017-06-09/javax.json.jar  \n",
            "  inflating: stanford-corenlp-full-2017-06-09/Makefile  \n",
            "  inflating: stanford-corenlp-full-2017-06-09/corenlp.sh  \n",
            "  inflating: stanford-corenlp-full-2017-06-09/joda-time-2.9-sources.jar  \n",
            "  inflating: stanford-corenlp-full-2017-06-09/stanford-corenlp-3.8.0-sources.jar  \n",
            "  inflating: stanford-corenlp-full-2017-06-09/stanford-corenlp-3.8.0.jar  \n",
            "  inflating: stanford-corenlp-full-2017-06-09/jollyday.jar  \n",
            "  inflating: stanford-corenlp-full-2017-06-09/ShiftReduceDemo.java  \n",
            "  inflating: stanford-corenlp-full-2017-06-09/SemgrexDemo.java  \n",
            "  inflating: stanford-corenlp-full-2017-06-09/LICENSE.txt  \n",
            "/content/EndEval\n",
            "\n",
            "*** NOW RUN: ***\n",
            "\n",
            "export CLASSPATH=$CLASSPATH:data-dir/corenlp/*\n",
            "\n",
            "****************\n"
          ]
        }
      ],
      "source": [
        "!mkdir data-dir/ \n",
        "!mkdir data-dir/train/\n",
        "!mkdir data-dir/val/\n",
        "!mkdir checkpoints/\n",
        "!bash utils/drqa/install_corenlp.sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vr9_JVSy7YRa",
        "outputId": "61071405-d2d9-4004-af6f-78c109acd252"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m730.2/730.2 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m248.2/248.2 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m776.3/776.3 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m86.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 kB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m71.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m306.1/306.1 kB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m88.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m880.6/880.6 kB\u001b[0m \u001b[31m44.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m593.6/593.6 kB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.1/19.1 MB\u001b[0m \u001b[31m42.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.4/125.4 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m57.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m52.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m237.5/237.5 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.5/163.5 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.7/132.7 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.7/13.7 MB\u001b[0m \u001b[31m89.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m671.1/671.1 kB\u001b[0m \u001b[31m44.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m88.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.0/184.0 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.9/178.9 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m71.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.6/79.6 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.1/51.1 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for fairscale (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for termcolor (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for jsonnet (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.14.1 requires torch==1.13.1, but you have torch 1.12.1 which is incompatible.\n",
            "torchaudio 0.13.1+cu116 requires torch==1.13.1, but you have torch 1.12.1 which is incompatible.\n",
            "en-core-web-sm 3.4.1 requires spacy<3.5.0,>=3.4.0, but you have spacy 3.3.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mDEPRECATION: git+https://github.com/deepset-ai/haystack.git#egg=farm-haystack[colab,faiss] contains an egg fragment with a non-PEP 508 name pip 25.0 will enforce this behaviour change. A possible replacement is to use the req @ url syntax, and remove the egg fragment. Discussion can be found at https://github.com/pypa/pip/issues/11617\u001b[0m\u001b[33m\n",
            "\u001b[0m  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m61.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m825.8/825.8 kB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m67.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m55.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m517.2/517.2 kB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m49.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m228.4/228.4 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m386.0/386.0 kB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.7/10.7 MB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.7/16.7 MB\u001b[0m \u001b[31m83.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m64.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m65.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m86.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.0/50.0 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m174.5/174.5 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.4/85.4 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.1/114.1 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.5/73.5 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m55.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.5/92.5 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m58.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m575.9/575.9 kB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.3/82.3 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.6/210.6 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.5/147.5 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.2/125.2 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m69.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.9/55.9 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/41.7 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for farm-haystack (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for python-docx (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for tika (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for databricks-cli (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.9.2 requires protobuf<3.20,>=3.9.2, but you have protobuf 3.20.2 which is incompatible.\n",
            "tensorboardx 2.5.1 requires protobuf<=3.20.1,>=3.8.0, but you have protobuf 3.20.2 which is incompatible.\n",
            "tensorboard 2.9.1 requires protobuf<3.20,>=3.9.2, but you have protobuf 3.20.2 which is incompatible.\n",
            "en-core-web-sm 3.4.1 requires spacy<3.5.0,>=3.4.0, but you have spacy 3.3.2 which is incompatible.\n",
            "allennlp 2.10.1 requires transformers<4.21,>=4.1, but you have transformers 4.25.1 which is incompatible.\n",
            "allennlp 2.10.1 requires wandb<0.13.0,>=0.10.0, but you have wandb 0.13.9 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -q --upgrade pip\n",
        "!pip install -q allennlp\n",
        "!pip install -q wandb==0.13.9 transformers==4.25.1 pytorch-lightning==1.9.0 onnxruntime==1.13.1 onnx==1.13.0 sentence-transformers==2.2.2 protobuf==3.20.2 git+https://github.com/deepset-ai/haystack.git#egg=farm-haystack[colab,faiss]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_EVzBWTe7esK",
        "outputId": "14a745bf-0394-45f9-b9b3-f72c0c8a55a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2023-02-05 05:02:27--  https://www.dropbox.com/s/fzne460dlfp5guj/train_data.csv?dl=0\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.5.18, 2620:100:601d:18::a27d:512\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.5.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /s/raw/fzne460dlfp5guj/train_data.csv [following]\n",
            "--2023-02-05 05:02:27--  https://www.dropbox.com/s/raw/fzne460dlfp5guj/train_data.csv\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc9143fb6efe939a1a858e76d5ec.dl.dropboxusercontent.com/cd/0/inline/B17oNM_pujx-Wk_HRrQr3crOwbgBAkd1MvVa535ZXuCamN0w4duoGJRBkkUqS80I9lvKwTuHbx4i2Ni9Y-p5zQPRWIWB7dN34Pi0D6VHntWJ7bHpPRnLsAbMwxsu17rRr1rR2EZQQC3lwHGkclt6_cPXSytFPNIUDZu2-HxAEGPigg/file# [following]\n",
            "--2023-02-05 05:02:28--  https://uc9143fb6efe939a1a858e76d5ec.dl.dropboxusercontent.com/cd/0/inline/B17oNM_pujx-Wk_HRrQr3crOwbgBAkd1MvVa535ZXuCamN0w4duoGJRBkkUqS80I9lvKwTuHbx4i2Ni9Y-p5zQPRWIWB7dN34Pi0D6VHntWJ7bHpPRnLsAbMwxsu17rRr1rR2EZQQC3lwHGkclt6_cPXSytFPNIUDZu2-HxAEGPigg/file\n",
            "Resolving uc9143fb6efe939a1a858e76d5ec.dl.dropboxusercontent.com (uc9143fb6efe939a1a858e76d5ec.dl.dropboxusercontent.com)... 162.125.5.15, 2620:100:6018:15::a27d:30f\n",
            "Connecting to uc9143fb6efe939a1a858e76d5ec.dl.dropboxusercontent.com (uc9143fb6efe939a1a858e76d5ec.dl.dropboxusercontent.com)|162.125.5.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 65646492 (63M) [text/plain]\n",
            "Saving to: ‘data-dir/train_data.csv’\n",
            "\n",
            "data-dir/train_data 100%[===================>]  62.60M  64.1MB/s    in 1.0s    \n",
            "\n",
            "2023-02-05 05:02:29 (64.1 MB/s) - ‘data-dir/train_data.csv’ saved [65646492/65646492]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://www.dropbox.com/s/fzne460dlfp5guj/train_data.csv?dl=0 -O data-dir/train_data.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EmwUFrXL9D9p",
        "outputId": "cf1c2e31-584d-4ab4-a65c-5a25b2d31fdc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100% 75038/75038 [02:32<00:00, 490.79it/s]\n",
            "len(df_train)=58856\n",
            "len(df_train.loc[df_train['answerable'] == True])=38777\n",
            "len(df_val)=8433\n",
            "len(df_val.loc[df_val['answerable'] == True])=5806\n",
            "len(df_test)=7749\n",
            "len(df_test.loc[df_test['answerable'] == True])=5542\n",
            "         title  ... title_id\n",
            "0      Beyoncé  ...        0\n",
            "1      Beyoncé  ...        0\n",
            "2      Beyoncé  ...        0\n",
            "3      Beyoncé  ...        0\n",
            "4      Beyoncé  ...        0\n",
            "...        ...  ...      ...\n",
            "75033   Matter  ...      360\n",
            "75034   Matter  ...      360\n",
            "75035   Matter  ...      360\n",
            "75036   Matter  ...      360\n",
            "75037   Matter  ...      360\n",
            "\n",
            "[75038 rows x 9 columns]\n"
          ]
        }
      ],
      "source": [
        "!python prepare_data.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hHXDebIv9JLd",
        "outputId": "91fe5d93-ae70-4c99-ec75-1357aad95537"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "env: CLASSPATH=$CLASSPATH:data-dir/corenlp/*\n",
            "$CLASSPATH:data-dir/corenlp/*\n"
          ]
        }
      ],
      "source": [
        "%env CLASSPATH=$CLASSPATH:data-dir/corenlp/*\n",
        "!echo $CLASSPATH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kem3dgWS949Q",
        "outputId": "f0cceb3b-aa1e-480b-831b-cd2c9bca54aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:faiss.loader:Loading faiss with AVX2 support.\n",
            "02/05/2023 05:10:50 AM: [ Loading faiss with AVX2 support. ]\n",
            "02/05/2023 05:10:50 AM: [ Loading faiss with AVX2 support. ]\n",
            "INFO:faiss.loader:Could not load library with AVX2 support due to:\n",
            "ModuleNotFoundError(\"No module named 'faiss.swigfaiss_avx2'\")\n",
            "02/05/2023 05:10:50 AM: [ Could not load library with AVX2 support due to:\n",
            "ModuleNotFoundError(\"No module named 'faiss.swigfaiss_avx2'\") ]\n",
            "02/05/2023 05:10:50 AM: [ Could not load library with AVX2 support due to:\n",
            "ModuleNotFoundError(\"No module named 'faiss.swigfaiss_avx2'\") ]\n",
            "INFO:faiss.loader:Loading faiss.\n",
            "02/05/2023 05:10:50 AM: [ Loading faiss. ]\n",
            "02/05/2023 05:10:50 AM: [ Loading faiss. ]\n",
            "INFO:faiss.loader:Successfully loaded faiss.\n",
            "02/05/2023 05:10:50 AM: [ Successfully loaded faiss. ]\n",
            "02/05/2023 05:10:50 AM: [ Successfully loaded faiss. ]\n",
            "INFO:torch.distributed.nn.jit.instantiator:Created a temporary directory at /tmp/tmpcsdh0w52\n",
            "02/05/2023 05:10:51 AM: [ Created a temporary directory at /tmp/tmpcsdh0w52 ]\n",
            "02/05/2023 05:10:51 AM: [ Created a temporary directory at /tmp/tmpcsdh0w52 ]\n",
            "INFO:torch.distributed.nn.jit.instantiator:Writing /tmp/tmpcsdh0w52/_remote_module_non_scriptable.py\n",
            "02/05/2023 05:10:51 AM: [ Writing /tmp/tmpcsdh0w52/_remote_module_non_scriptable.py ]\n",
            "02/05/2023 05:10:51 AM: [ Writing /tmp/tmpcsdh0w52/_remote_module_non_scriptable.py ]\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "Reading data csv\n",
            "7749\n",
            "using drqa\n",
            "1661it [00:03, 474.78it/s]\n",
            "                                                                              text    id\n",
            "0  Frédéric François Chopin (/ˈʃoʊpæn/; French pronunciation: ​[fʁe.de.ʁik fʁɑ̃...  66_0\n",
            "1  He gained and has maintained renown worldwide as one of the leading musician...  66_1\n",
            "2  Chopin was born in what was then the Duchy of Warsaw, and grew up in Warsaw,...  66_2\n",
            "3  A child prodigy, he completed his musical education and composed his earlier...  66_3\n",
            "0                                            At the age of 21 he settled in Paris.  67_0\n",
            "INFO:root:Reading into database...\n",
            "02/05/2023 05:10:59 AM: [ Reading into database... ]\n",
            "02/05/2023 05:10:59 AM: [ Reading into database... ]\n",
            "  0% 0/1 [00:00<?, ?it/s]\n",
            "100% 1/1 [00:00<00:00,  8.91it/s]\n",
            "1it [00:00,  8.90it/s]\n",
            "100% 1/1 [00:00<00:00,  8.86it/s]\n",
            "INFO:root:Read 8200 docs.\n",
            "02/05/2023 05:10:59 AM: [ Read 8200 docs. ]\n",
            "02/05/2023 05:10:59 AM: [ Read 8200 docs. ]\n",
            "INFO:root:Committing...\n",
            "02/05/2023 05:10:59 AM: [ Committing... ]\n",
            "02/05/2023 05:10:59 AM: [ Committing... ]\n",
            "Counting words...\n",
            "INFO:root:Mapping...\n",
            "02/05/2023 05:10:59 AM: [ Mapping... ]\n",
            "02/05/2023 05:10:59 AM: [ Mapping... ]\n",
            "INFO:root:-------------------------Batch 1/10-------------------------\n",
            "02/05/2023 05:10:59 AM: [ -------------------------Batch 1/10------------------------- ]\n",
            "02/05/2023 05:10:59 AM: [ -------------------------Batch 1/10------------------------- ]\n",
            "INFO:root:-------------------------Batch 2/10-------------------------\n",
            "02/05/2023 05:11:08 AM: [ -------------------------Batch 2/10------------------------- ]\n",
            "02/05/2023 05:11:08 AM: [ -------------------------Batch 2/10------------------------- ]\n",
            "INFO:root:-------------------------Batch 3/10-------------------------\n",
            "02/05/2023 05:11:13 AM: [ -------------------------Batch 3/10------------------------- ]\n",
            "02/05/2023 05:11:13 AM: [ -------------------------Batch 3/10------------------------- ]\n",
            "INFO:root:-------------------------Batch 4/10-------------------------\n",
            "02/05/2023 05:11:16 AM: [ -------------------------Batch 4/10------------------------- ]\n",
            "02/05/2023 05:11:16 AM: [ -------------------------Batch 4/10------------------------- ]\n",
            "INFO:root:-------------------------Batch 5/10-------------------------\n",
            "02/05/2023 05:11:19 AM: [ -------------------------Batch 5/10------------------------- ]\n",
            "02/05/2023 05:11:19 AM: [ -------------------------Batch 5/10------------------------- ]\n",
            "INFO:root:-------------------------Batch 6/10-------------------------\n",
            "02/05/2023 05:11:21 AM: [ -------------------------Batch 6/10------------------------- ]\n",
            "02/05/2023 05:11:21 AM: [ -------------------------Batch 6/10------------------------- ]\n",
            "INFO:root:-------------------------Batch 7/10-------------------------\n",
            "02/05/2023 05:11:23 AM: [ -------------------------Batch 7/10------------------------- ]\n",
            "02/05/2023 05:11:23 AM: [ -------------------------Batch 7/10------------------------- ]\n",
            "INFO:root:-------------------------Batch 8/10-------------------------\n",
            "02/05/2023 05:11:27 AM: [ -------------------------Batch 8/10------------------------- ]\n",
            "02/05/2023 05:11:27 AM: [ -------------------------Batch 8/10------------------------- ]\n",
            "INFO:root:-------------------------Batch 9/10-------------------------\n",
            "02/05/2023 05:11:30 AM: [ -------------------------Batch 9/10------------------------- ]\n",
            "02/05/2023 05:11:30 AM: [ -------------------------Batch 9/10------------------------- ]\n",
            "INFO:root:-------------------------Batch 10/10-------------------------\n",
            "02/05/2023 05:11:34 AM: [ -------------------------Batch 10/10------------------------- ]\n",
            "02/05/2023 05:11:34 AM: [ -------------------------Batch 10/10------------------------- ]\n",
            "INFO:root:Creating sparse matrix...\n",
            "02/05/2023 05:11:37 AM: [ Creating sparse matrix... ]\n",
            "02/05/2023 05:11:37 AM: [ Creating sparse matrix... ]\n",
            "Making tfidf vectors...\n",
            "Getting word-doc frequencies...\n",
            "Saving to data-dir/val/sqlite_con-tfidf-ngram=3-hash=33554432-tokenizer=corenlp.npz\n",
            "INFO:root:Reading into database...\n",
            "02/05/2023 05:11:43 AM: [ Reading into database... ]\n",
            "02/05/2023 05:11:43 AM: [ Reading into database... ]\n",
            "  0% 0/1 [00:00<?, ?it/s]\n",
            "100% 1/1 [00:00<00:00,  3.19it/s]\n",
            "1it [00:00,  3.22it/s]\n",
            "100% 1/1 [00:00<00:00,  3.18it/s]\n",
            "INFO:root:Read 12091 docs.\n",
            "02/05/2023 05:11:44 AM: [ Read 12091 docs. ]\n",
            "02/05/2023 05:11:44 AM: [ Read 12091 docs. ]\n",
            "INFO:root:Committing...\n",
            "02/05/2023 05:11:44 AM: [ Committing... ]\n",
            "02/05/2023 05:11:44 AM: [ Committing... ]\n",
            "Counting words...\n",
            "INFO:root:Mapping...\n",
            "02/05/2023 05:11:44 AM: [ Mapping... ]\n",
            "02/05/2023 05:11:44 AM: [ Mapping... ]\n",
            "INFO:root:-------------------------Batch 1/11-------------------------\n",
            "02/05/2023 05:11:44 AM: [ -------------------------Batch 1/11------------------------- ]\n",
            "02/05/2023 05:11:44 AM: [ -------------------------Batch 1/11------------------------- ]\n",
            "INFO:root:-------------------------Batch 2/11-------------------------\n",
            "02/05/2023 05:12:07 AM: [ -------------------------Batch 2/11------------------------- ]\n",
            "02/05/2023 05:12:07 AM: [ -------------------------Batch 2/11------------------------- ]\n",
            "INFO:root:-------------------------Batch 3/11-------------------------\n",
            "02/05/2023 05:12:24 AM: [ -------------------------Batch 3/11------------------------- ]\n",
            "02/05/2023 05:12:24 AM: [ -------------------------Batch 3/11------------------------- ]\n",
            "INFO:root:-------------------------Batch 4/11-------------------------\n",
            "02/05/2023 05:12:36 AM: [ -------------------------Batch 4/11------------------------- ]\n",
            "02/05/2023 05:12:36 AM: [ -------------------------Batch 4/11------------------------- ]\n",
            "INFO:root:-------------------------Batch 5/11-------------------------\n",
            "02/05/2023 05:12:51 AM: [ -------------------------Batch 5/11------------------------- ]\n",
            "02/05/2023 05:12:51 AM: [ -------------------------Batch 5/11------------------------- ]\n",
            "INFO:root:-------------------------Batch 6/11-------------------------\n",
            "02/05/2023 05:13:01 AM: [ -------------------------Batch 6/11------------------------- ]\n",
            "02/05/2023 05:13:01 AM: [ -------------------------Batch 6/11------------------------- ]\n",
            "INFO:root:-------------------------Batch 7/11-------------------------\n",
            "02/05/2023 05:13:13 AM: [ -------------------------Batch 7/11------------------------- ]\n",
            "02/05/2023 05:13:13 AM: [ -------------------------Batch 7/11------------------------- ]\n",
            "INFO:root:-------------------------Batch 8/11-------------------------\n",
            "02/05/2023 05:13:27 AM: [ -------------------------Batch 8/11------------------------- ]\n",
            "02/05/2023 05:13:27 AM: [ -------------------------Batch 8/11------------------------- ]\n",
            "INFO:root:-------------------------Batch 9/11-------------------------\n",
            "02/05/2023 05:13:40 AM: [ -------------------------Batch 9/11------------------------- ]\n",
            "02/05/2023 05:13:40 AM: [ -------------------------Batch 9/11------------------------- ]\n",
            "INFO:root:-------------------------Batch 10/11-------------------------\n",
            "02/05/2023 05:13:56 AM: [ -------------------------Batch 10/11------------------------- ]\n",
            "02/05/2023 05:13:56 AM: [ -------------------------Batch 10/11------------------------- ]\n",
            "INFO:root:-------------------------Batch 11/11-------------------------\n",
            "02/05/2023 05:14:09 AM: [ -------------------------Batch 11/11------------------------- ]\n",
            "02/05/2023 05:14:09 AM: [ -------------------------Batch 11/11------------------------- ]\n",
            "INFO:root:Creating sparse matrix...\n",
            "02/05/2023 05:14:09 AM: [ Creating sparse matrix... ]\n",
            "02/05/2023 05:14:09 AM: [ Creating sparse matrix... ]\n",
            "Making tfidf vectors...\n",
            "Getting word-doc frequencies...\n",
            "Saving to data-dir/train/sqlite_con-tfidf-ngram=3-hash=33554432-tokenizer=corenlp.npz\n",
            "1803it [00:05, 339.88it/s]\n",
            "                                                                              text     id\n",
            "0  The domestic dog (Canis lupus familiaris or Canis familiaris) is a domestica...  897_0\n",
            "0  Although initially thought to have originated as a manmade variant of an ext...  898_0\n",
            "1  Being the oldest domesticated animal, their long association with people has...  898_1\n",
            "0  Dogs perform many roles for people, such as hunting, herding, pulling loads,...  899_0\n",
            "1  This impact on human society has given them the nickname \"man's best friend\"...  899_1\n",
            "INFO:root:Reading into database...\n",
            "02/05/2023 05:14:22 AM: [ Reading into database... ]\n",
            "02/05/2023 05:14:22 AM: [ Reading into database... ]\n",
            "  0% 0/1 [00:00<?, ?it/s]\n",
            "100% 1/1 [00:00<00:00,  7.70it/s]\n",
            "1it [00:00,  7.70it/s]\n",
            "100% 1/1 [00:00<00:00,  7.67it/s]\n",
            "INFO:root:Read 8726 docs.\n",
            "02/05/2023 05:14:22 AM: [ Read 8726 docs. ]\n",
            "02/05/2023 05:14:22 AM: [ Read 8726 docs. ]\n",
            "INFO:root:Committing...\n",
            "02/05/2023 05:14:22 AM: [ Committing... ]\n",
            "02/05/2023 05:14:22 AM: [ Committing... ]\n",
            "Counting words...\n",
            "INFO:root:Mapping...\n",
            "02/05/2023 05:14:22 AM: [ Mapping... ]\n",
            "02/05/2023 05:14:22 AM: [ Mapping... ]\n",
            "INFO:root:-------------------------Batch 1/11-------------------------\n",
            "02/05/2023 05:14:22 AM: [ -------------------------Batch 1/11------------------------- ]\n",
            "02/05/2023 05:14:22 AM: [ -------------------------Batch 1/11------------------------- ]\n",
            "INFO:root:-------------------------Batch 2/11-------------------------\n",
            "02/05/2023 05:14:28 AM: [ -------------------------Batch 2/11------------------------- ]\n",
            "02/05/2023 05:14:28 AM: [ -------------------------Batch 2/11------------------------- ]\n",
            "INFO:root:-------------------------Batch 3/11-------------------------\n",
            "02/05/2023 05:14:33 AM: [ -------------------------Batch 3/11------------------------- ]\n",
            "02/05/2023 05:14:33 AM: [ -------------------------Batch 3/11------------------------- ]\n",
            "INFO:root:-------------------------Batch 4/11-------------------------\n",
            "02/05/2023 05:14:37 AM: [ -------------------------Batch 4/11------------------------- ]\n",
            "02/05/2023 05:14:37 AM: [ -------------------------Batch 4/11------------------------- ]\n",
            "INFO:root:-------------------------Batch 5/11-------------------------\n",
            "02/05/2023 05:14:41 AM: [ -------------------------Batch 5/11------------------------- ]\n",
            "02/05/2023 05:14:41 AM: [ -------------------------Batch 5/11------------------------- ]\n",
            "INFO:root:-------------------------Batch 6/11-------------------------\n",
            "02/05/2023 05:14:44 AM: [ -------------------------Batch 6/11------------------------- ]\n",
            "02/05/2023 05:14:44 AM: [ -------------------------Batch 6/11------------------------- ]\n",
            "INFO:root:-------------------------Batch 7/11-------------------------\n",
            "02/05/2023 05:14:46 AM: [ -------------------------Batch 7/11------------------------- ]\n",
            "02/05/2023 05:14:46 AM: [ -------------------------Batch 7/11------------------------- ]\n",
            "INFO:root:-------------------------Batch 8/11-------------------------\n",
            "02/05/2023 05:14:49 AM: [ -------------------------Batch 8/11------------------------- ]\n",
            "02/05/2023 05:14:49 AM: [ -------------------------Batch 8/11------------------------- ]\n",
            "INFO:root:-------------------------Batch 9/11-------------------------\n",
            "02/05/2023 05:14:50 AM: [ -------------------------Batch 9/11------------------------- ]\n",
            "02/05/2023 05:14:50 AM: [ -------------------------Batch 9/11------------------------- ]\n",
            "INFO:root:-------------------------Batch 10/11-------------------------\n",
            "02/05/2023 05:14:52 AM: [ -------------------------Batch 10/11------------------------- ]\n",
            "02/05/2023 05:14:52 AM: [ -------------------------Batch 10/11------------------------- ]\n",
            "INFO:root:-------------------------Batch 11/11-------------------------\n",
            "02/05/2023 05:14:55 AM: [ -------------------------Batch 11/11------------------------- ]\n",
            "02/05/2023 05:14:55 AM: [ -------------------------Batch 11/11------------------------- ]\n",
            "INFO:root:Creating sparse matrix...\n",
            "02/05/2023 05:14:55 AM: [ Creating sparse matrix... ]\n",
            "02/05/2023 05:14:55 AM: [ Creating sparse matrix... ]\n",
            "Making tfidf vectors...\n",
            "Getting word-doc frequencies...\n",
            "Saving to data-dir/test/sqlite_con-tfidf-ngram=3-hash=33554432-tokenizer=corenlp.npz\n",
            "INFO:root:Initializing ranker...\n",
            "02/05/2023 05:15:02 AM: [ Initializing ranker... ]\n",
            "02/05/2023 05:15:02 AM: [ Initializing ranker... ]\n",
            "02/05/2023 05:15:02 AM: [ Initializing ranker... ]\n",
            "INFO:root:Initializing ranker...\n",
            "02/05/2023 05:15:04 AM: [ Initializing ranker... ]\n",
            "02/05/2023 05:15:04 AM: [ Initializing ranker... ]\n",
            "02/05/2023 05:15:04 AM: [ Initializing ranker... ]\n",
            "02/05/2023 05:15:04 AM: [ Initializing ranker... ]\n",
            "saving model and optimizer at checkpoints/bert-medium-finetuned-squadv2_train_logits/model_optimizer.pt\n",
            "INFO:wandb:Watching\n",
            "02/05/2023 05:15:07 AM: [ Watching ]\n",
            "02/05/2023 05:15:07 AM: [ Watching ]\n",
            "02/05/2023 05:15:07 AM: [ Watching ]\n",
            "02/05/2023 05:15:07 AM: [ Watching ]\n",
            "Creating train dataset\n",
            "100% 1840/1840 [01:03<00:00, 29.02it/s]\n",
            "Creating val dataset\n",
            "100% 264/264 [00:06<00:00, 39.34it/s]\n",
            "length of val dataset: 8433\n",
            "Epoch 1:   4% 133/3679 [03:32<50:13,  1.18batch/s, loss=0.114]"
          ]
        }
      ],
      "source": [
        "!WANDB_MODE=disabled python main.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "woRXeCKR99SB"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
